The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.
`low_cpu_mem_usage` was None, now set to True since model is quantized.
/u/wzhan/.conda/envs/prepack/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
You are calling `save_pretrained` to a 4-bit converted model, but your `bitsandbytes` version doesn't support it. If you want to save 4-bit models, make sure to have `bitsandbytes>=0.41.3` installed.
/u/wzhan/.conda/envs/prepack/lib/python3.9/site-packages/bitsandbytes/nn/modules.py:224: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.
  warnings.warn(f'Input type into Linear4bit is torch.float16, but bnb_4bit_compute_type=torch.float32 (default). This will lead to slow inference or training speed.')
Loaded 400 records from /u/wzhan/prepack-workspace/dataset/realdata_downsample/code.sampled.0.csv
[FIRST-THEN-0] batch=1, wait_window=0.2000s, num_requests=3
[FIRST-THEN-0] batch=2, wait_window=0.0000s, num_requests=18
[FIRST-THEN-0] batch=3, wait_window=0.0000s, num_requests=26
[FIRST-THEN-0] batch=4, wait_window=0.0000s, num_requests=18
[FIRST-THEN-0] batch=5, wait_window=0.0000s, num_requests=15
[FIRST-THEN-0] batch=6, wait_window=0.0000s, num_requests=7
[FIRST-THEN-0] batch=7, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=8, wait_window=0.0000s, num_requests=5
[FIRST-THEN-0] batch=9, wait_window=0.0000s, num_requests=4
[FIRST-THEN-0] batch=10, wait_window=0.0000s, num_requests=10
[FIRST-THEN-0] batch=11, wait_window=0.0000s, num_requests=7
[FIRST-THEN-0] batch=12, wait_window=0.0000s, num_requests=5
[FIRST-THEN-0] batch=13, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=14, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=15, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=16, wait_window=0.0000s, num_requests=8
[FIRST-THEN-0] batch=17, wait_window=0.0000s, num_requests=6
[FIRST-THEN-0] batch=18, wait_window=0.0000s, num_requests=5
[FIRST-THEN-0] batch=19, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=20, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=21, wait_window=0.0000s, num_requests=4
[FIRST-THEN-0] batch=22, wait_window=0.0000s, num_requests=4
[FIRST-THEN-0] batch=23, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=24, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=25, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=26, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=27, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=28, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=29, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=30, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=31, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=32, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=33, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=34, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=35, wait_window=0.0000s, num_requests=2
[FIRST-THEN-0] batch=36, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=37, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=38, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0] batch=39, wait_window=0.0000s, num_requests=3
[FIRST-THEN-0] batch=40, wait_window=0.0000s, num_requests=4
[FIRST-THEN-0] batch=41, wait_window=0.0000s, num_requests=8
[FIRST-THEN-0] batch=42, wait_window=0.0000s, num_requests=10
[FIRST-THEN-0] batch=43, wait_window=0.0000s, num_requests=9
[FIRST-THEN-0] batch=44, wait_window=0.0000s, num_requests=8
[FIRST-THEN-0] batch=45, wait_window=0.0000s, num_requests=12
[FIRST-THEN-0] batch=46, wait_window=0.0000s, num_requests=15
[FIRST-THEN-0] batch=47, wait_window=0.0000s, num_requests=25
[FIRST-THEN-0] batch=48, wait_window=0.0000s, num_requests=29
[FIRST-THEN-0] batch=49, wait_window=0.0000s, num_requests=33
[FIRST-THEN-0] batch=50, wait_window=0.0000s, num_requests=28
[FIRST-THEN-0] batch=51, wait_window=0.0000s, num_requests=29
[FIRST-THEN-0] batch=52, wait_window=0.0000s, num_requests=1
[FIRST-THEN-0-PREPACK] avg per-input TTFT=4.8487s
[SIZE-AIMD] batch=1, desired_size=4, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=2, desired_size=2, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=3, desired_size=1, backlog_before=2, actual_batch_size=1
[SIZE-AIMD] batch=4, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=5, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=6, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=7, desired_size=11, backlog_before=6, actual_batch_size=6
[SIZE-AIMD] batch=8, desired_size=5, backlog_before=11, actual_batch_size=5
[SIZE-AIMD] batch=9, desired_size=15, backlog_before=8, actual_batch_size=8
[SIZE-AIMD] batch=10, desired_size=7, backlog_before=12, actual_batch_size=7
[SIZE-AIMD] batch=11, desired_size=16, backlog_before=12, actual_batch_size=12
[SIZE-AIMD] batch=12, desired_size=8, backlog_before=7, actual_batch_size=7
[SIZE-AIMD] batch=13, desired_size=4, backlog_before=8, actual_batch_size=4
[SIZE-AIMD] batch=14, desired_size=14, backlog_before=7, actual_batch_size=7
[SIZE-AIMD] batch=15, desired_size=7, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=16, desired_size=3, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=17, desired_size=13, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=18, desired_size=6, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=19, desired_size=3, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=20, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=21, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=22, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=23, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=24, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=25, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=26, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=27, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=28, desired_size=11, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=29, desired_size=5, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=30, desired_size=2, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=31, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=32, desired_size=11, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=33, desired_size=5, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=34, desired_size=2, backlog_before=5, actual_batch_size=2
[SIZE-AIMD] batch=35, desired_size=12, backlog_before=5, actual_batch_size=5
[SIZE-AIMD] batch=36, desired_size=6, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=37, desired_size=3, backlog_before=4, actual_batch_size=3
[SIZE-AIMD] batch=38, desired_size=13, backlog_before=5, actual_batch_size=5
[SIZE-AIMD] batch=39, desired_size=6, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=40, desired_size=3, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=41, desired_size=1, backlog_before=2, actual_batch_size=1
[SIZE-AIMD] batch=42, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=43, desired_size=11, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=44, desired_size=5, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=45, desired_size=2, backlog_before=3, actual_batch_size=2
[SIZE-AIMD] batch=46, desired_size=12, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=47, desired_size=6, backlog_before=8, actual_batch_size=6
[SIZE-AIMD] batch=48, desired_size=16, backlog_before=8, actual_batch_size=8
[SIZE-AIMD] batch=49, desired_size=8, backlog_before=7, actual_batch_size=7
[SIZE-AIMD] batch=50, desired_size=4, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=51, desired_size=2, backlog_before=3, actual_batch_size=2
[SIZE-AIMD] batch=52, desired_size=12, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=53, desired_size=6, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=54, desired_size=3, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=55, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=56, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=57, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=58, desired_size=11, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=59, desired_size=5, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=60, desired_size=2, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=61, desired_size=12, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=62, desired_size=6, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=63, desired_size=3, backlog_before=2, actual_batch_size=2
[SIZE-AIMD] batch=64, desired_size=1, backlog_before=2, actual_batch_size=1
[SIZE-AIMD] batch=65, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=66, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=67, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=68, desired_size=1, backlog_before=1, actual_batch_size=1
[SIZE-AIMD] batch=69, desired_size=11, backlog_before=3, actual_batch_size=3
[SIZE-AIMD] batch=70, desired_size=5, backlog_before=4, actual_batch_size=4
[SIZE-AIMD] batch=71, desired_size=15, backlog_before=8, actual_batch_size=8
[SIZE-AIMD] batch=72, desired_size=7, backlog_before=10, actual_batch_size=7
[SIZE-AIMD] batch=73, desired_size=16, backlog_before=11, actual_batch_size=11
[SIZE-AIMD] batch=74, desired_size=8, backlog_before=7, actual_batch_size=7
[SIZE-AIMD] batch=75, desired_size=16, backlog_before=10, actual_batch_size=10
[SIZE-AIMD] batch=76, desired_size=8, backlog_before=13, actual_batch_size=8
[SIZE-AIMD] batch=77, desired_size=16, backlog_before=16, actual_batch_size=16
Traceback (most recent call last):
  File "/u/wzhan/prepack-workspace/prepack_dynamic/test_stream_wait_aimd.py", line 955, in <module>
    avg_ttft_size_aimd_prepack = simulate_size_aimd_wait(
  File "/u/wzhan/prepack-workspace/prepack_dynamic/test_stream_wait_aimd.py", line 694, in simulate_size_aimd_wait
    batch_latency = run_batch_with_metric(
  File "/u/wzhan/prepack-workspace/prepack_dynamic/test_stream_wait_aimd.py", line 90, in run_batch_with_metric
    _ = fn(*fn_args)
  File "/u/wzhan/prepack-workspace/prepack_dynamic/profiling_time_and_memory.py", line 60, in TTFT_with_prepacking
    cache, final_tokens, attention_mask = unpack_kv(
  File "/u/wzhan/prepack-workspace/prepack_dynamic/dataset_utils.py", line 157, in unpack_kv
    final_tokens[original_index] = prompt[-1]
KeyboardInterrupt
